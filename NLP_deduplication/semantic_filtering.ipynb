{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12cec2d4-c07a-47f5-a2e0-9dda9c470bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/9c/4c/4563ebe001ff30dca9d7ed12e471fa098d9759712980cde1fd03a3a44fb7/protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/431.5 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 81.9/431.5 kB 1.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 163.8/431.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 327.7/431.5 kB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 348.2/431.5 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 431.5/431.5 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-5.28.3\n"
     ]
    }
   ],
   "source": [
    "! pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c4eb3b0-e5e7-48b9-bad0-6c2c4a1cbe84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Device Name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel , AutoTokenizer , AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0146bf20-86b9-4fde-baea-a1f87c23f3db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e2c9a54-4130-4bc8-a308-36deb9ec6e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize mBERT tokenizer and model\n",
    "mbert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "mbert_model = BertModel.from_pretrained(\"bert-base-multilingual-cased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6edad533-0e81-41e5-9ace-6a16fef0eed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae0625294c946308e85178953aebce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indic_tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "indic_model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c335e89-6dcf-4925-bce0-ba6f8d31ca0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get embeddings for a list of sentences with tqdm progress bar\n",
    "def mbert_get_embeddings(sentences):\n",
    "    embeddings = []\n",
    "    mbert_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence in tqdm(sentences, desc=\"Generating embeddings\", unit=\"sentence\"):\n",
    "            # Tokenize and prepare input tensors using encode_plus\n",
    "            inputs = mbert_tokenizer.encode_plus(\n",
    "                sentence,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=128\n",
    "            )\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "            # Get embeddings (using CLS token representation)\n",
    "            outputs = mbert_model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(cls_embedding.flatten())\n",
    "\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Function to filter near-duplicate sentences based on cosine similarity with tqdm\n",
    "def filter_duplicates(sentences, embeddings, threshold=0.90):\n",
    "    filtered_sentences = []\n",
    "    filtered_embeddings = []\n",
    "\n",
    "    for i, embedding in tqdm(enumerate(embeddings), desc=\"Filtering duplicates\", total=len(embeddings)):\n",
    "        # Calculate cosine similarity with already accepted embeddings\n",
    "        if len(filtered_embeddings) == 0:\n",
    "            filtered_sentences.append(sentences[i])\n",
    "            filtered_embeddings.append(embedding)\n",
    "            continue\n",
    "\n",
    "        similarities = cosine_similarity([embedding], filtered_embeddings)[0]\n",
    "        max_similarity = max(similarities)\n",
    "\n",
    "        # Only add the sentence if similarity is below the threshold\n",
    "        if max_similarity < threshold:\n",
    "            filtered_sentences.append(sentences[i])\n",
    "            filtered_embeddings.append(embedding)\n",
    "\n",
    "    return filtered_sentences\n",
    "\n",
    "def indic_get_embeddings(sentences):\n",
    "    embeddings = []\n",
    "    indic_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sentence in tqdm(sentences, desc=\"Generating embeddings\"):\n",
    "            inputs = indic_tokenizer(\n",
    "                sentence,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=128\n",
    "            )\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "            # Get embeddings and average them\n",
    "            outputs = indic_model(**inputs)\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            sentence_embedding = torch.mean(token_embeddings, dim=1).cpu().numpy().flatten()\n",
    "            embeddings.append(sentence_embedding)\n",
    "\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f108baff-74ec-489c-b950-6650165659d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your sentences (Updated column name to \"Sentences\")\n",
    "data = pd.read_csv(\"syntactic_filtered_sentences.csv\")\n",
    "sentences = data['Sentences'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a51eb33d-eb9e-4125-9ed5-b83dfd995aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating mbert embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|███████████████████████████████████████████████| 86519/86519 [21:09<00:00, 68.17sentence/s]\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings for the sentences with a progress bar\n",
    "print(\"Generating mbert embeddings...\")\n",
    "mbert_embeddings = get_embeddings(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6942573-37c4-489e-a8b8-52dd0cdcb637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating indic embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|█████████████████████████████████████████████████████| 86519/86519 [39:58<00:00, 36.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings for the sentences with a progress bar\n",
    "print(\"Generating indic embeddings...\")\n",
    "indic_embeddings = indic_get_embeddings(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "293940c7-3144-4621-b45b-73e6846b0819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mbert)Filtering near-duplicate sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering duplicates: 100%|████████████████████████████████████████████████████| 86519/86519 [2:27:39<00:00,  9.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter out near-duplicate sentences with a progress bar\n",
    "print(\"(mbert)Filtering near-duplicate sentences...\")\n",
    "mbert_filtered_sentences = filter_duplicates(sentences, mbert_embeddings, threshold=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87644ddc-53e6-45fb-98a3-e6e71aecef82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(indic)Filtering near-duplicate sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering duplicates: 100%|████████████████████████████████████████████████████| 86519/86519 [1:24:18<00:00, 17.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter out near-duplicate sentences with a progress bar\n",
    "print(\"(indic)Filtering near-duplicate sentences...\")\n",
    "indic_filtered_sentences = filter_duplicates(sentences, mbert_embeddings, threshold=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f11c1d39-c19e-4b8c-932c-639617fd955f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of sentences: 86519\n",
      "(indic embedding) Number of unique sentences after filtering: 26011\n",
      "(Mbert embedding) Number of unique sentences after filtering: 46189\n"
     ]
    }
   ],
   "source": [
    "# Output the results\n",
    "print(f\"Original number of sentences: {len(sentences)}\")\n",
    "print(f\"(indic embedding) Number of unique sentences after filtering: {len(indic_filtered_sentences)}\")\n",
    "print(f\"(Mbert embedding) Number of unique sentences after filtering: {len(mbert_filtered_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f36320a-04c3-4c77-8518-1169f0bcd075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered sentences saved to 'filtered_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the filtered sentences to a CSV file\n",
    "mbert_filtered_df = pd.DataFrame(mbert_filtered_sentences, columns=[\"Sentences\"])\n",
    "mbert_filtered_df.to_csv(\"97%_mbert_filtered_sentences.csv\", index=False)\n",
    "print(\"Filtered sentences saved to 'filtered_sentences.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac2ee654-cb4b-43c6-bb26-410189e0920d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered sentences saved to 'filtered_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the filtered sentences to a CSV file\n",
    "indic_filtered_df = pd.DataFrame(indic_filtered_sentences, columns=[\"Sentences\"])\n",
    "indic_filtered_df.to_csv(\"indic_filtered_sentences.csv\", index=False)\n",
    "print(\"Filtered sentences saved to 'filtered_sentences.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
